{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic regression regularization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVSlz1xJGK+eGKgzPexgzC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Looma1116/Seungjoon_Lee/blob/main/w4_Logistic_regression_regularization(wine).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "kdbLkO33P2TN",
        "outputId": "ad6354b1-4a7d-4771-ff51-7c9c262c1a7a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "dat_wine = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',header=None)\n",
        "\n",
        "dat_wine.columns = ['class label', 'alchohol', 'malic acid','ash','alcalinity of ash','magnesium','total phenols',\n",
        "                    'flavanoids','nonflavanoid phenols','proanthocyanins','color intensity','hue','OD208','proline']\n",
        "print('class label : ',np.unique(dat_wine['class label']))\n",
        "dat_wine.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class label :  [1 2 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class label</th>\n",
              "      <th>alchohol</th>\n",
              "      <th>malic acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity of ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>OD208</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class label  alchohol  malic acid  ...   hue  OD208  proline\n",
              "0            1     14.23        1.71  ...  1.04   3.92     1065\n",
              "1            1     13.20        1.78  ...  1.05   3.40     1050\n",
              "2            1     13.16        2.36  ...  1.03   3.17     1185\n",
              "3            1     14.37        1.95  ...  0.86   3.45     1480\n",
              "4            1     13.24        2.59  ...  1.04   2.93      735\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQVrUYMlNsvY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x,y = dat_wine.iloc[:,1:].values, dat_wine.iloc[:,0].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state =1, stratify = y)\n",
        "#stratify = y : y의 비율을 균등하게 뽑아준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPbzgL_Hbvzr"
      },
      "source": [
        "#Logistic Regression with L2 or L1 Regularization\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr2_10 = LogisticRegression(penalty='l2', C=10.0, solver='saga') #L2 with C(=1/λ) = 10\n",
        "lr2_1 = LogisticRegression(penalty='l2', C=1.0, solver='saga') #L2 with C(=1/λ) = 1\n",
        "lr2_0_1 = LogisticRegression(penalty='l2', C=0.1, solver='saga') #L2 with C(=1/λ) = 0.1\n",
        "\n",
        "lr1_10 = LogisticRegression(penalty='l1', C=10.0, solver='saga') #L1 with C(=1/λ) = 10\n",
        "lr1_1 = LogisticRegression(penalty='l1', C=1.0, solver='saga') #L1 with C(=1/λ) = 1\n",
        "lr1_0_1 = LogisticRegression(penalty='l1', C=0.1, solver='saga') #L1 with C(=1/λ) = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9np1zrCdiF7"
      },
      "source": [
        "#standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "sc.fit(x_train)\n",
        "x_train_std = sc.transform(x_train)\n",
        "x_test_std = sc.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDOln6kpczyB",
        "outputId": "52469b58-bbe2-43f1-d12a-6c5ea0e599d8"
      },
      "source": [
        "#규제화 방법(L2 or L1)과 규제강도 C(=1/λ)에 따른 accuracy score\n",
        "lr2_10.fit(x_train_std,y_train)\n",
        "print('Training accuracy with L2 and λ=0.1 : ', lr2_10.score(x_train_std,y_train))\n",
        "print('Test accuracy with L2 and λ=0.1 : ', lr2_10.score(x_test_std,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy with L2 and λ=0.1 :  1.0\n",
            "Test accuracy with L2 and λ=0.1 :  0.9814814814814815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-PjSbTvduBf",
        "outputId": "59f1519c-09e0-4a8f-8b18-3053fe71f903"
      },
      "source": [
        "lr2_1.fit(x_train_std,y_train)\n",
        "print('Training accuracy with L2 and λ=1 : ', lr2_1.score(x_train_std,y_train))\n",
        "print('Test accuracy with L2 and λ=1 : ', lr2_1.score(x_test_std,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy with L2 and λ=1 :  1.0\n",
            "Test accuracy with L2 and λ=1 :  0.9814814814814815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBu8BTeld1Tk",
        "outputId": "7c18c3e8-253f-48c6-c45c-9bbd68033420"
      },
      "source": [
        "lr2_0_1.fit(x_train_std,y_train)\n",
        "print('Training accuracy with L2 and λ=10 : ', lr2_0_1.score(x_train_std,y_train))\n",
        "print('Test accuracy with L2 and λ=10 : ', lr2_0_1.score(x_test_std,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy with L2 and λ=10 :  1.0\n",
            "Test accuracy with L2 and λ=10 :  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOmToGiue7bG",
        "outputId": "2109f9b6-4b95-410d-b4e9-bf9d6772c890"
      },
      "source": [
        "lr1_10.fit(x_train_std,y_train)\n",
        "print('Training accuracy with L1 and λ=0.1 : ', lr1_10.score(x_train_std,y_train))\n",
        "print('Test accuracy with L1 and λ=0.1 : ', lr1_10.score(x_test_std,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy with L1 and λ=0.1 :  1.0\n",
            "Test accuracy with L1 and λ=0.1 :  0.9814814814814815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGGrZfGffFJS",
        "outputId": "316ab94f-6d0d-42f3-8ce6-e7920cfa40aa"
      },
      "source": [
        "lr1_1.fit(x_train_std,y_train)\n",
        "print('Training accuracy with L1 and λ=1 : ', lr1_1.score(x_train_std,y_train))\n",
        "print('Test accuracy with L1 and λ=1 : ', lr1_1.score(x_test_std,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy with L1 and λ=1 :  1.0\n",
            "Test accuracy with L1 and λ=1 :  0.9814814814814815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MLDMHS2fFsA",
        "outputId": "8f94bd8d-df5d-40a2-e1da-47ddc15e6171"
      },
      "source": [
        "lr1_0_1.fit(x_train_std,y_train)\n",
        "print('Training accuracy with L1 and λ=10 : ', lr1_0_1.score(x_train_std,y_train))\n",
        "print('Test accuracy with L1 and λ=10 : ', lr1_0_1.score(x_test_std,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy with L1 and λ=10 :  0.967741935483871\n",
            "Test accuracy with L1 and λ=10 :  0.9444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYAWdA-bhjoI",
        "outputId": "33779f16-e4e5-43eb-f21b-af1c6940c1a8"
      },
      "source": [
        "#계수 추정치 관찰\n",
        "\n",
        "print('L2, λ=0.1 : ', lr2_10.coef_)\n",
        "print('L2, λ=1 : ', lr2_1.coef_)\n",
        "print('L2, λ=10 : ', lr2_0_1.coef_)\n",
        "print('L1, λ=0.1 : ', lr1_10.coef_)\n",
        "print('L1, λ=1 : ', lr1_1.coef_)\n",
        "print('L1, λ=10 : ', lr1_0_1.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2, λ=0.1 :  [[ 1.24706675  0.17033327  0.38248395 -1.53201352  0.08292232  0.47406897\n",
            "   0.78595851 -0.31176983  0.10774894  0.14161551  0.04314275  0.93102396\n",
            "   1.41058615]\n",
            " [-1.56338839 -0.44812508 -1.26685581  1.22427589 -0.29870728 -0.59621253\n",
            "   0.88714005  0.42364538  0.39704482 -1.28205437  1.14691786  0.11634197\n",
            "  -1.78039905]\n",
            " [ 0.31632164  0.27779181  0.88437186  0.30773763  0.21578496  0.12214356\n",
            "  -1.67309856 -0.11187555 -0.50479376  1.14043885 -1.19006061 -1.04736594\n",
            "   0.3698129 ]]\n",
            "L2, λ=1 :  [[ 0.75500287  0.06176829  0.23388027 -0.89280266  0.02665121  0.29455888\n",
            "   0.56051561 -0.20725046  0.13360216  0.12755554  0.1019343   0.61759429\n",
            "   0.90950445]\n",
            " [-0.98654451 -0.32330323 -0.65174715  0.66812418 -0.22942115 -0.20785467\n",
            "   0.43819283  0.19891147  0.24362592 -0.7805909   0.63685175  0.08533315\n",
            "  -1.034542  ]\n",
            " [ 0.23154164  0.26153494  0.41786688  0.22467848  0.20276994 -0.08670422\n",
            "  -0.99870845  0.00833898 -0.37722808  0.65303536 -0.73878605 -0.70292744\n",
            "   0.12503755]]\n",
            "L2, λ=10 :  [[ 0.41030807 -0.03150277  0.13679623 -0.41134566  0.05384404  0.22358219\n",
            "   0.31668493 -0.15967853  0.11367782  0.07038461  0.1110545   0.30980478\n",
            "   0.51691269]\n",
            " [-0.54265893 -0.20155783 -0.25666212  0.28073458 -0.14836656 -0.04063563\n",
            "   0.12451121  0.08292739  0.10084264 -0.44574321  0.27317689  0.09643684\n",
            "  -0.51872548]\n",
            " [ 0.13235086  0.2330606   0.11986589  0.13061108  0.09452253 -0.18294656\n",
            "  -0.44119614  0.07675114 -0.21452046  0.37535861 -0.38423139 -0.40624163\n",
            "   0.00181279]]\n",
            "L1, λ=0.1 :  [[ 1.18221532  0.          0.17624873 -1.56839141  0.          0.23386684\n",
            "   0.81160102 -0.03486961  0.          0.          0.          0.86372566\n",
            "   1.66378708]\n",
            " [-1.77735866 -0.46803663 -1.49484289  1.02083563 -0.23133294 -0.41118879\n",
            "   0.62052685  0.40929316  0.22712472 -1.39723136  1.16720057  0.\n",
            "  -2.02992082]\n",
            " [ 0.06968815  0.09051502  0.79143737  0.02005867  0.22428218  0.\n",
            "  -1.94762867  0.         -0.47990434  1.16833264 -1.26455101 -1.02520019\n",
            "   0.        ]]\n",
            "L1, λ=1 :  [[ 0.03851588  0.          0.         -1.18659263  0.          0.\n",
            "   0.02756912  0.          0.          0.          0.          0.6290988\n",
            "   0.94811384]\n",
            " [-1.56299367 -0.15012945 -0.76369142  0.03062528 -0.06796618  0.\n",
            "   0.          0.12926532  0.         -1.04204321  0.2127918   0.\n",
            "  -1.23784024]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "  -2.0548723   0.         -0.05398993  0.22798439 -0.82562349 -0.66745569\n",
            "   0.        ]]\n",
            "L1, λ=10 :  [[ 0.          0.          0.         -0.04187218  0.          0.\n",
            "   0.23313245  0.          0.          0.          0.          0.\n",
            "   0.84029674]\n",
            " [-0.8348105   0.          0.          0.          0.          0.\n",
            "   0.          0.          0.         -0.42343241  0.          0.\n",
            "  -0.2065894 ]\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "  -0.60075676  0.          0.          0.10471141 -0.35230987 -0.52170925\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}